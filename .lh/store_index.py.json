{
    "sourceFile": "store_index.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1765623410509,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1765623865351,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,55 @@\n+from dotenv import load_dotenv\r\n+from pinecone import Pinecone\r\n+import os\r\n+load_dotenv()\r\n+from langchain_community.embeddings import HuggingFaceEmbeddings\r\n+from pinecone import Pinecone, ServerlessSpec\r\n+from langchain_pinecone import PineconeVectorStore\r\n+\r\n+from src.helper import load_pdf_files, filter_to_minimal_docs,text_split, download_embeddings\r\n+\r\n+PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\r\n+GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\r\n+\r\n+\r\n+os.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY\r\n+os.environ[\"GROQ_API_KEY\"]=GROQ_API_KEY\r\n+\r\n+\r\n+\r\n+extracted_data = load_pdf_files(r\"D:\\Desktop\\medical chatbot\\data\")\r\n+filter_data=filter_to_minimal_docs(extracted_data)\r\n+texts_chunk=text_split(filter_data)\r\n+\r\n+embeddings=download_embeddings()\r\n+\r\n+\r\n+\r\n+pc=Pinecone(api_key=PINECONE_API_KEY)\r\n+\r\n+\r\n+\r\n+index_name = \"medical-chatbot\"\r\n+\r\n+# Initialize Pinecone client\r\n+#pc = Pinecone(api_key=PINECONE_API_KEY)\r\n+\r\n+# Create index if it doesn't exist\r\n+if not pc.has_index(index_name):\r\n+    pc.create_index(\r\n+        name=index_name,\r\n+        dimension=384,  # dimension of your embedding model\r\n+        metric=\"cosine\",  # cosine similarity\r\n+        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\r\n+    )\r\n+\r\n+# Access the index (correct method)\r\n+index = pc.Index(index_name)\r\n+\r\n+\r\n+docsearch=PineconeVectorStore.from_documents(\r\n+    documents=texts_chunk,\r\n+    embeddings=embeddings,\r\n+    index_name=index_name\r\n+)\r\n+#यह code आपके  को embeddings में बदलकर Pinecone index में store कर रहा है, ताकि बाद में आप fast similarity search कर सकें।\r\n"
                },
                {
                    "date": 1765623873959,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,9 +15,8 @@\n os.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY\r\n os.environ[\"GROQ_API_KEY\"]=GROQ_API_KEY\r\n \r\n \r\n-\r\n extracted_data = load_pdf_files(r\"D:\\Desktop\\medical chatbot\\data\")\r\n filter_data=filter_to_minimal_docs(extracted_data)\r\n texts_chunk=text_split(filter_data)\r\n \r\n@@ -52,58 +51,4 @@\n     embeddings=embeddings,\r\n     index_name=index_name\r\n )\r\n #यह code आपके  को embeddings में बदलकर Pinecone index में store कर रहा है, ताकि बाद में आप fast similarity search कर सकें।\r\n-from dotenv import load_dotenv\r\n-from pinecone import Pinecone\r\n-import os\r\n-load_dotenv()\r\n-from langchain_community.embeddings import HuggingFaceEmbeddings\r\n-from pinecone import Pinecone, ServerlessSpec\r\n-from langchain_pinecone import PineconeVectorStore\r\n-\r\n-from src.helper import load_pdf_files, filter_to_minimal_docs,text_split, download_embeddings\r\n-\r\n-PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\r\n-GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\r\n-\r\n-\r\n-os.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY\r\n-os.environ[\"GROQ_API_KEY\"]=GROQ_API_KEY\r\n-\r\n-\r\n-extracted_data=load_pdf_files(data=r\"D:\\Desktop\\medical chatbot\\data\")\r\n-filter_data=filter_to_minimal_docs(extracted_data)\r\n-texts_chunk=text_split(filter_data)\r\n-\r\n-embeddings=download_embeddings()\r\n-\r\n-\r\n-\r\n-pc=Pinecone(api_key=PINECONE_API_KEY)\r\n-\r\n-\r\n-\r\n-index_name = \"medical-chatbot\"\r\n-\r\n-# Initialize Pinecone client\r\n-#pc = Pinecone(api_key=PINECONE_API_KEY)\r\n-\r\n-# Create index if it doesn't exist\r\n-if not pc.has_index(index_name):\r\n-    pc.create_index(\r\n-        name=index_name,\r\n-        dimension=384,  # dimension of your embedding model\r\n-        metric=\"cosine\",  # cosine similarity\r\n-        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\r\n-    )\r\n-\r\n-# Access the index (correct method)\r\n-index = pc.Index(index_name)\r\n-\r\n-\r\n-docsearch=PineconeVectorStore.from_documents(\r\n-    documents=texts_chunk,\r\n-    embeddings=embeddings,\r\n-    index_name=index_name\r\n-)\r\n-#यह code आपके  को embeddings में बदलकर Pinecone index में store कर रहा है, ताकि बाद में आप fast similarity search कर सकें।\r\n"
                },
                {
                    "date": 1765624201055,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,8 +47,8 @@\n \r\n \r\n docsearch=PineconeVectorStore.from_documents(\r\n     documents=texts_chunk,\r\n-    embeddings=embeddings,\r\n+    embedding=embeddings,\r\n     index_name=index_name\r\n )\r\n #यह code आपके  को embeddings में बदलकर Pinecone index में store कर रहा है, ताकि बाद में आप fast similarity search कर सकें।\r\n"
                },
                {
                    "date": 1765625264092,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,9 +1,9 @@\n from dotenv import load_dotenv\r\n from pinecone import Pinecone\r\n import os\r\n load_dotenv()\r\n-from langchain_community.embeddings import HuggingFaceEmbeddings\r\n+from langchain_huggingface import HuggingFaceEmbeddings\r\n from pinecone import Pinecone, ServerlessSpec\r\n from langchain_pinecone import PineconeVectorStore\r\n \r\n from src.helper import load_pdf_files, filter_to_minimal_docs,text_split, download_embeddings\r\n"
                }
            ],
            "date": 1765623410509,
            "name": "Commit-0",
            "content": "from dotenv import load_dotenv\r\nfrom pinecone import Pinecone\r\nimport os\r\nload_dotenv()\r\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\r\nfrom pinecone import Pinecone, ServerlessSpec\r\nfrom langchain_pinecone import PineconeVectorStore\r\n\r\nfrom src.helper import load_pdf_files, filter_to_minimal_docs,text_split, download_embeddings\r\n\r\nPINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\")\r\nGROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")\r\n\r\n\r\nos.environ[\"PINECONE_API_KEY\"]=PINECONE_API_KEY\r\nos.environ[\"GROQ_API_KEY\"]=GROQ_API_KEY\r\n\r\n\r\nextracted_data=load_pdf_files(data=r\"D:\\Desktop\\medical chatbot\\data\")\r\nfilter_data=filter_to_minimal_docs(extracted_data)\r\ntexts_chunk=text_split(filter_data)\r\n\r\nembeddings=download_embeddings()\r\n\r\n\r\n\r\npc=Pinecone(api_key=PINECONE_API_KEY)\r\n\r\n\r\n\r\nindex_name = \"medical-chatbot\"\r\n\r\n# Initialize Pinecone client\r\n#pc = Pinecone(api_key=PINECONE_API_KEY)\r\n\r\n# Create index if it doesn't exist\r\nif not pc.has_index(index_name):\r\n    pc.create_index(\r\n        name=index_name,\r\n        dimension=384,  # dimension of your embedding model\r\n        metric=\"cosine\",  # cosine similarity\r\n        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\r\n    )\r\n\r\n# Access the index (correct method)\r\nindex = pc.Index(index_name)\r\n\r\n\r\ndocsearch=PineconeVectorStore.from_documents(\r\n    documents=texts_chunk,\r\n    embeddings=embeddings,\r\n    index_name=index_name\r\n)\r\n#यह code आपके  को embeddings में बदलकर Pinecone index में store कर रहा है, ताकि बाद में आप fast similarity search कर सकें।\r\n"
        }
    ]
}